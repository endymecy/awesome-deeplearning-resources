# Natural Language Model

- Energy-Based Models for Text. [`arxiv`](https://arxiv.org/abs/2004.10188)

## Dialog

- Recipes for building an open-domain chatbot.  [`arxiv`](https://arxiv.org/abs/2004.13637)

## Generate Adversarial Model

- FastWordBug: A Fast Method To Generate Adversarial Text Against NLP Applications. [`arxiv`](https://arxiv.org/pdf/2002.00760.pdf)

## Information Extraction

- Rapid Adaptation of BERT for Information Extraction on Domain-Specific Business Documents. [`arxiv`](https://arxiv.org/pdf/2002.01861.pdf)


## Language Model

- BERT-of-Theseus: Compressing BERT by Progressive Module Replacing. [`arxiv`](https://arxiv.org/abs/2002.02925) [`code`](https://github.com/JetRunner/BERT-of-Theseus)
- BERTweet: A pre-trained language model for English Tweets. [`arxiv`](https://arxiv.org/abs/2005.10200) [`code`](https://github.com/VinAIResearch/BERTweet)
- Blank Language Models. [`arxiv`](https://arxiv.org/abs/2002.03079)
- Controlling Computation versus Quality for Neural Sequence Models. [`arxiv`](https://arxiv.org/abs/2002.07106)
- ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators. [`arxiv`](https://openreview.net/pdf?id=r1xMH1BtvB) [`code`](https://github.com/google-research/electra) :star:
- Extending Multilingual BERT to Low-Resource Languages. [`arxiv`](https://arxiv.org/abs/2004.13640)
- Limits of Detecting Text Generated by Large-Scale Language Models. [`arxiv`](https://arxiv.org/abs/2002.03438)
- PALM: Pre-training an Autoencoding&Autoregressive Language Model for Context-conditioned Generation. [`arxiv`](https://arxiv.org/abs/2004.07159) 
- Pretrained Transformers Improve Out-of-Distribution Robustness. [`arxiv`](https://arxiv.org/abs/2004.06100)
- Semantics-aware BERT for Language Understanding. [`arxiv`](https://arxiv.org/pdf/1909.02209.pdf) [`code`](https://github.com/cooelf/SemBERT)

## Pos-tagging

- Joint Embedding in Named Entity Linking on Sentence Level. [`arxiv`](https://arxiv.org/abs/2002.04936)

## QA

- AmbigQA: Answering Ambiguous Open-domain Questions. [`arxiv`](https://arxiv.org/abs/2004.10645) 
- Asking and Answering Questions to Evaluate the Factual Consistency of Summaries. [`arxiv`](https://arxiv.org/abs/2004.04228)
- Conversational Question Answering over Passages by Leveraging Word Proximity Networks. [`arxiv`](https://arxiv.org/abs/2004.13117) [`code`](https://github.com/magkai/CROWN)
- Probing Emergent Semantics in Predictive Agents via Question Answering. [`arxiv`](https://arxiv.org/abs/2006.01016)
- Unsupervised Commonsense Question Answering with Self-Talk. [`arxiv`](https://arxiv.org/abs/2004.05483) [`code`](https://github.com/vered1986/self_talk)

## Text Classification

- Light-Weighted CNN for Text Classification. [`arxiv`](https://arxiv.org/pdf/2004.07922.pdf)
- Multi-Label Text Classification using Attention-based Graph Neural Network. [`arxiv`](https://arxiv.org/abs/2003.11644)

## Text Generation

- NUBIA: NeUral Based Interchangeability Assessor for Text Generation. [`arxiv`](https://arxiv.org/abs/2004.14667)
- Polarized-VAE: Proximity Based Disentangled Representation Learning for Text Generation. [`arxiv`](https://arxiv.org/abs/2004.10809)
- Reverse Engineering Configurations of Neural Text Generation Models.  [`arxiv`](https://arxiv.org/abs/2004.06201)

